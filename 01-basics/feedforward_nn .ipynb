{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2G9cgfeiAeXb"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "ZocnLPyXRV_P"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyper-parameters\n",
        "input_size = 784\n",
        "hidden_size = 500\n",
        "num_classes = 10\n",
        "num_epochs =  5\n",
        "batch_size = 100\n",
        "learning_rate = 0.001"
      ],
      "metadata": {
        "id": "6jK6MaZjRi36"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = torchvision.datasets.MNIST(root='../../data',\n",
        "                                           train=True,\n",
        "                                           transform=transforms.ToTensor(),\n",
        "                                           download=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='../../data',\n",
        "                                          train=False,\n",
        "                                          transform=transforms.ToTensor())\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfHwhis3RxYc",
        "outputId": "0be557da-4279-4e1c-9caf-6c80c475be47"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 69850491.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../../data/MNIST/raw/train-images-idx3-ubyte.gz to ../../data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../../data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 31521127.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../../data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|██████████| 1648877/1648877 [00:00<00:00, 19966312.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../../data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 5927358.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../../data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A neural network using PyTorch, which has an input layer, a hidden layer, and an output layer.\n",
        "\n",
        "The network is trained to perform a task with a certain number of input features (input_size), a hidden layer of neurons (hidden_size), and produce a certain number of output classes (num_classes).\n",
        "\n",
        "During training, it uses the CrossEntropyLoss as a measure of the difference between predicted and actual values, and the Adam optimizer to adjust the model's parameters for better performance.\n",
        "\n",
        "The network is then trained using a training dataset (train_loader).\n",
        "\n",
        "The goal is to minimize the loss and improve the model's ability to make accurate predictions."
      ],
      "metadata": {
        "id": "24FQtZj8V93d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        return out\n",
        "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "# Train the model\n",
        "total_step = len(train_loader)"
      ],
      "metadata": {
        "id": "J9qdoOqQSAl1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ReLU activation function is applied using self.relu. ReLU introduces non-linearity to the model by setting all negative values in the output of the linear layer to zero and leaving positive values unchanged. This helps the network learn complex patterns and relationships in the data."
      ],
      "metadata": {
        "id": "7D6WB8WyW-re"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        # Move tensors to the configured device\n",
        "        images = images.reshape(-1, 28*28).to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i+1) % 100 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
        "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPHznPouSj-P",
        "outputId": "3667342a-d13b-4332-aa7d-908eb46197a9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Step [100/600], Loss: 0.3431\n",
            "Epoch [1/5], Step [200/600], Loss: 0.2816\n",
            "Epoch [1/5], Step [300/600], Loss: 0.2268\n",
            "Epoch [1/5], Step [400/600], Loss: 0.2757\n",
            "Epoch [1/5], Step [500/600], Loss: 0.1113\n",
            "Epoch [1/5], Step [600/600], Loss: 0.1671\n",
            "Epoch [2/5], Step [100/600], Loss: 0.1346\n",
            "Epoch [2/5], Step [200/600], Loss: 0.0698\n",
            "Epoch [2/5], Step [300/600], Loss: 0.1747\n",
            "Epoch [2/5], Step [400/600], Loss: 0.0576\n",
            "Epoch [2/5], Step [500/600], Loss: 0.0207\n",
            "Epoch [2/5], Step [600/600], Loss: 0.1396\n",
            "Epoch [3/5], Step [100/600], Loss: 0.1033\n",
            "Epoch [3/5], Step [200/600], Loss: 0.0391\n",
            "Epoch [3/5], Step [300/600], Loss: 0.0599\n",
            "Epoch [3/5], Step [400/600], Loss: 0.1216\n",
            "Epoch [3/5], Step [500/600], Loss: 0.1270\n",
            "Epoch [3/5], Step [600/600], Loss: 0.0590\n",
            "Epoch [4/5], Step [100/600], Loss: 0.1446\n",
            "Epoch [4/5], Step [200/600], Loss: 0.0311\n",
            "Epoch [4/5], Step [300/600], Loss: 0.0958\n",
            "Epoch [4/5], Step [400/600], Loss: 0.0637\n",
            "Epoch [4/5], Step [500/600], Loss: 0.0294\n",
            "Epoch [4/5], Step [600/600], Loss: 0.0328\n",
            "Epoch [5/5], Step [100/600], Loss: 0.0123\n",
            "Epoch [5/5], Step [200/600], Loss: 0.0102\n",
            "Epoch [5/5], Step [300/600], Loss: 0.0237\n",
            "Epoch [5/5], Step [400/600], Loss: 0.0172\n",
            "Epoch [5/5], Step [500/600], Loss: 0.0404\n",
            "Epoch [5/5], Step [600/600], Loss: 0.0484\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model\n",
        "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.reshape(-1, 28*28).to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))\n",
        "\n",
        "# Save the model checkpoint\n",
        "torch.save(model.state_dict(), 'model.ckpt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DH2E61-tSsL9",
        "outputId": "b5014f98-9133-424a-ebd1-e97b5ba72c4d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 97.88 %\n"
          ]
        }
      ]
    }
  ]
}