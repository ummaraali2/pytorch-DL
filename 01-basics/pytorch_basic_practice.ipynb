{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Basic practices of Deep Learning using PyTorch\n",
        "\n",
        "## I. Example 1 for Automatic Differentiation (autograd)\n",
        "\n",
        "Automatic Differentiation in PyTorch\n",
        "\n",
        "It's a system that automatically computes gradients of expressions with respect to input variables. Gradients are essential for optimizing neural network models during the training process using techniques like gradient descent."
      ],
      "metadata": {
        "id": "4XcyMJxLhmrb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JFego9hoNEJr"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "first things first, linear equations and creating tensors, performing predictions, etc but what is nn? neural network... to understanr refer neural network's youtube video by 3blue1brown, (my favourite channel) to build stronger intuitions behind understanding neural networks, weights and biases, and understanding them, reason behind calculating losses, gradient descents, and much more..."
      ],
      "metadata": {
        "id": "qsareOqVTZ1c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor(1., requires_grad=True)\n",
        "w = torch.tensor(2., requires_grad=True)\n",
        "b = torch.tensor(3., requires_grad=True)"
      ],
      "metadata": {
        "id": "wu0xdMX0NVnl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "grad true means that it is gointo track the operations performed on/with x, w, b"
      ],
      "metadata": {
        "id": "Bor9z7MtR778"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = w * x + b"
      ],
      "metadata": {
        "id": "vCv2GnRUObz0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "this is a simple linear equation\n",
        "In this case, the requires_grad has tracked the operations and built a compuattion graph"
      ],
      "metadata": {
        "id": "_OSYYpJ8SRds"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y.backward()"
      ],
      "metadata": {
        "id": "aHGCPxXIPd3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "the backward pass now performs differentiation with respect to y"
      ],
      "metadata": {
        "id": "ch2WTyh8TEsl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(x.grad)\n",
        "print(w.grad)\n",
        "print(b.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGMIj0oxPh1G",
        "outputId": "e0d559b2-ffcd-4d77-c20b-0e41f19b257a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.)\n",
            "tensor(1.)\n",
            "tensor(1.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## II. Example 2"
      ],
      "metadata": {
        "id": "HeaVmRnriynH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(10, 3)\n",
        "y = torch.randn(10,2)"
      ],
      "metadata": {
        "id": "uM_HKKdKPoep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "linear = nn.Linear(3, 2)\n",
        "print('w', linear.weight)\n",
        "print('b', linear.bias)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BlLd_ZojUqs_",
        "outputId": "0d9f5d4f-8bbe-46b6-e181-fd57e81d4949"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w Parameter containing:\n",
            "tensor([[-0.1423,  0.2529, -0.0654],\n",
            "        [ 0.5331, -0.4084,  0.4343]], requires_grad=True)\n",
            "b Parameter containing:\n",
            "tensor([-0.3153, -0.4255], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhAwusXpXH_T",
        "outputId": "561e73cb-05dc-41ff-c869-74aa586259b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-7.6141e-01,  1.0809e-04],\n",
              "        [-1.3537e+00,  1.7671e+00],\n",
              "        [-1.0346e+00, -2.4248e-01],\n",
              "        [ 9.9441e-01,  6.7304e-01],\n",
              "        [ 4.7188e-01, -2.1565e+00],\n",
              "        [ 2.3015e-01, -6.5607e-01],\n",
              "        [ 2.3410e-01, -4.8376e-01],\n",
              "        [ 1.5548e+00, -1.3485e-01],\n",
              "        [ 1.3650e-02,  2.0139e+00],\n",
              "        [ 7.7922e-02, -9.2036e-02]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(linear.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "r62zBO5kid8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = linear(x)"
      ],
      "metadata": {
        "id": "ilIHXRR3ih-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ny8nC4ihi9Ff",
        "outputId": "4c12a503-d33a-4189-f5ca-66f5633b8d21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.2893, -0.2346],\n",
              "        [-0.6698,  0.4193],\n",
              "        [-0.4674,  0.0723],\n",
              "        [-0.2020, -0.5157],\n",
              "        [-0.3000, -0.4427],\n",
              "        [-0.2821, -1.0992],\n",
              "        [-0.0706, -0.0329],\n",
              "        [-0.6721,  1.0849],\n",
              "        [-0.2303, -0.7887],\n",
              "        [-0.2509, -0.4587]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = criterion(pred, y)\n",
        "print('loss: ', loss.item())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNDxYc4xjHhd",
        "outputId": "307b39c4-6490-47cc-982e-50a129e31a71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss:  1.2359490394592285\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss.backward()"
      ],
      "metadata": {
        "id": "-PODtSrulO5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print ('dL/dw: ', linear.weight.grad)\n",
        "print ('dL/db: ', linear.bias.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_9ei1PtlP_V",
        "outputId": "a1881c5d-ff8c-4db9-bcd0-fba2cb4aebdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dL/dw:  tensor([[ 0.1418, -0.0057, -0.6323],\n",
            "        [ 0.2210,  0.1109,  0.3854]])\n",
            "dL/db:  tensor([-0.3862, -0.2684])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer.step()"
      ],
      "metadata": {
        "id": "eoGT6g5umV2F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = linear(x)\n"
      ],
      "metadata": {
        "id": "eMjb0jgKmdxn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtE-IIm0mmNY",
        "outputId": "a380b977-2e95-43df-ac3d-04feb62f8a1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.2863, -0.2343],\n",
              "        [-0.6646,  0.4207],\n",
              "        [-0.4707,  0.0741],\n",
              "        [-0.1961, -0.5147],\n",
              "        [-0.2926, -0.4407],\n",
              "        [-0.2873, -1.0892],\n",
              "        [-0.0519, -0.0411],\n",
              "        [-0.6533,  1.0778],\n",
              "        [-0.2235, -0.7845],\n",
              "        [-0.2486, -0.4568]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = criterion(pred, y)\n",
        "print('loss after 1 step optimization: ', loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TsvmJYMXmscy",
        "outputId": "e323fe47-ffaa-417f-ca84-82f2c7ac4b24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss after 1 step optimization:  1.22749924659729\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(linear.parameters(), lr=0.1)"
      ],
      "metadata": {
        "id": "ylrJ6xkCm6uB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = linear(x)\n",
        "\n",
        "# Compute loss.\n",
        "loss = criterion(pred, y)\n",
        "print('loss: ', loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AiWNcouonTj1",
        "outputId": "7d8b8c3d-4475-47a2-816d-13e4dd280b82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss:  1.22749924659729\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss.backward()"
      ],
      "metadata": {
        "id": "2HdfYxxnnYyG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer.step()"
      ],
      "metadata": {
        "id": "mYPUo79BnbDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = linear(x)\n",
        "loss = criterion(pred, y)\n",
        "print('loss after 1 step optimization: ', loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRq4DLWtneRX",
        "outputId": "a9b9b66b-4bcf-4c4b-d542-3acfa46a53c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss after 1 step optimization:  1.0838451385498047\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYF5MELCngLk",
        "outputId": "9c7ba107-36ef-47b3-8241-67363dcf511b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.2259, -0.2270],\n",
              "        [-0.5618,  0.4473],\n",
              "        [-0.5356,  0.1099],\n",
              "        [-0.0794, -0.4947],\n",
              "        [-0.1443, -0.3995],\n",
              "        [-0.3912, -0.8909],\n",
              "        [ 0.3200, -0.2051],\n",
              "        [-0.2812,  0.9368],\n",
              "        [-0.0890, -0.7011],\n",
              "        [-0.2021, -0.4187]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# summary\n",
        "# created x, y random tensors\n",
        "# built linear nn with 3 inputs and 2 outputs\n",
        "# assigned loss function - MSELoss()\n",
        "# optimizer method - SGD with LR = 0.01\n",
        "# pred - linear(x)\n",
        "# calculate loss\n",
        "# perform loss backward\n",
        "# optimizer - 1 step gradient descent\n",
        "# again linear(x)\n",
        "# loss calculated\n",
        "# print and see loss\n",
        "# inc lr because data is not so large and/or lr is very small? i dont know"
      ],
      "metadata": {
        "id": "ZU6-GN1Xniys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## III. loading data from numpy"
      ],
      "metadata": {
        "id": "LiSXD1p6i_VB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array([[1,2], [3,4]])\n",
        "y = torch.from_numpy(x)\n",
        "z = y.numpy()"
      ],
      "metadata": {
        "id": "8Il9-90qn1Gy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## IV. Input pipeline"
      ],
      "metadata": {
        "id": "GH4jZCHyjKMC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now Im downloading CIFAR10 data set"
      ],
      "metadata": {
        "id": "lo7K99AeTAOX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = torchvision.datasets.CIFAR10(root='../data,',\n",
        "                                             train = True,\n",
        "                                             transform = transforms.ToTensor(),\n",
        "                                             download = True)"
      ],
      "metadata": {
        "id": "nh6XDEI8zF33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da68998d-63b0-4191-9a63-afa894c89ac1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../data,/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:01<00:00, 94630117.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data,/cifar-10-python.tar.gz to ../data,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image, label = train_dataset[0]\n",
        "print (image.size())\n",
        "print(label)\n",
        "# 1 2 3 ...32...32\n",
        "# Just fetching this data ->"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMiCR2uUS62w",
        "outputId": "312f0158-9975-4ba3-85b8-a7e02bbff287"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 32, 32])\n",
            "6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The DataLoader typically uses a queue to load and enqueue batches of data in parallel with the training process. The queue helps manage the flow of data between the CPU (where data is loaded) and the GPU (where the model is trained). This is especially important when the data loading process is slower than the model training process, as it allows the model to continuously receive batches without waiting for each batch to be loaded.\n",
        "\n",
        "So lets create the train_loader... this provides queues and threads to efficiently parallalize loading of bayches.\n"
      ],
      "metadata": {
        "id": "6XjCMJz_WuY6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.utils.data\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                      batch_size=64,\n",
        "                                      shuffle=True)\n",
        "# shuffling is used to create randomness in loading the batches..so it can prevent from our model to learn patterns specific to the order but in reality order means nothing for the data. so we dont need thaat."
      ],
      "metadata": {
        "id": "RMIpHzErTSRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "after this get the train_loader iterable in data_iter so you can get the next batches using next. this is usually used to manually inspect the batches. We often use a loop to iterate through batches and perform trainign."
      ],
      "metadata": {
        "id": "qGxriR32bqda"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_iter = iter(train_loader)\n",
        "\n"
      ],
      "metadata": {
        "id": "kQtAZ7zwZ4OC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images, labels = next(data_iter)"
      ],
      "metadata": {
        "id": "-LF2v-2rZ5Iy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "loop ->\n"
      ],
      "metadata": {
        "id": "ujw_C8Jeb938"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for images, labels in train_loader:\n",
        "    # Training code should be written here.\n",
        "    pass"
      ],
      "metadata": {
        "id": "11TW7u4aaN5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "components of an input pipeline:\n",
        "1. Data Loading: Loading data from storage\n",
        "2. Data Preprocessing: Preprocessing involves transforming the raw data into a format suitable for training.\n",
        "3. Batching: Grouping the data into batches. Training a machine learning model with batches of data, rather than individual samples.\n",
        "4. Shuffling: Randomizing the order of data samples.\n",
        "5. Prefetching: Overlapping data loading and model training.\n",
        "\n",
        "```\n",
        "\n",
        "## V. Input pipeline for custom dataset\n",
        "Now...\n",
        "\n",
        "Custom Dataset: Created by the user to handle specific data formats, sources, or preprocessing steps. It involves defining a class that inherits from torch.utils.data.Dataset and implementing the __getitem__ and __len__ methods.\n",
        "\n",
        "Pre-built Dataset: Provided by libraries like torchvision and is ready-made for common tasks. These datasets are often well-known and used for benchmarking and experimentation.\n",
        "\n",
        "Custom Dataset: Users define how data is loaded from files, databases, or any source within the __getitem__ method.\n",
        "\n",
        "Pre-built Dataset: Data loading logic is predefined and often includes mechanisms for downloading, extracting, and organizing data."
      ],
      "metadata": {
        "id": "QtTvJ5K8cuji"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self):\n",
        "\n",
        "        # 1. Initialize file paths or a list of file names.\n",
        "        pass\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        # 1. Read one data from file (e.g. using numpy.fromfile, PIL.Image.open).\n",
        "        # 2. Preprocess the data (e.g. torchvision.Transform).\n",
        "        # 3. Return a data pair (e.g. image and label).\n",
        "        pass\n",
        "    def __len__(self):\n",
        "        # You should change 0 to the total size of your dataset.\n",
        "        return 1\n",
        "\n",
        "custom_dataset = CustomDataset()\n",
        "train_loader = torch.utils.data.DataLoader(dataset=custom_dataset,\n",
        "                                           batch_size=64,\n",
        "                                           shuffle=True)"
      ],
      "metadata": {
        "id": "6JrS3Mszamde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VI. How to download and load the pretrained model.\n",
        "\n",
        "here im using resnet-18 which is a pretrained image recognition model with 1000 classes/categories\n",
        "while we use this model, the training is freezed so we can only fine-tune the params based on our i/p and outputs..and the model training will not learn anything from my data, because itsfreezed.\n",
        "then, a random image tensor is created with the outputs size 100 i.e., 100 classes/categories because i just have 100 categories..\n",
        "so i can used this trained model and use my parameters."
      ],
      "metadata": {
        "id": "zBSrINIUjjhn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resnet = torchvision.models.resnet18(pretrained=True)\n",
        "for param in resnet.parameters():\n",
        "  param.requires_grad = False\n",
        "\n",
        "resnet.fc = nn.Linear(resnet.fc.in_features, 100)\n",
        "\n",
        "images = torch.randn(64, 3, 224, 224)\n",
        "outputs = resnet(images)\n",
        "print(outputs.size())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LhNjYnP7e61y",
        "outputId": "94063474-c0ab-4aa6-baac-52715daefba6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 100])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "Input Layer      Hidden Layer      Output Layer\n",
        "  o o o             o o o o          o o o\n",
        "   \\ \\ \\           / / / /           \\ \\ \\\n",
        "    \\ \\ \\         / / / /             \\ \\ \\\n",
        "     \\ \\ \\       / / / /               \\ \\ \\\n",
        "      \\ \\ \\     / / / /                 \\ \\ \\\n",
        "       \\ \\ \\   / / / /                   \\ \\ \\\n",
        "        \\ \\ \\ / / / /                     \\ \\ \\\n",
        "```\n",
        "\n",
        "```\n",
        "Input Layer      Hidden Layer      New Output Layer\n",
        "  o o o             o o o o               o o o\n",
        "   \\ \\ \\           / / / / \\              | | |\n",
        "    \\ \\ \\         / / / /   \\             | | |\n",
        "     \\ \\ \\       / / / /     \\            | | |\n",
        "      \\ \\ \\     / / / /       \\           | | |\n",
        "       \\ \\ \\   / / / /         \\          | | |\n",
        "        \\ \\ \\ / / / /           \\         | | |\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "GITMm2GOk1gc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VII. Save and load the model."
      ],
      "metadata": {
        "id": "hBjjal55vxbz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(resnet, 'model.ckpt')\n",
        "model = torch.load('model.ckpt')\n",
        "\n",
        "# we can also save and load just the the model parameters.\n",
        "\n",
        "torch.save(resnet.state_dict(),'params.ckpt')\n",
        "resnet.load_state_dict(torch.load('params.ckpt'))\n",
        "\n",
        "# ckpt - checkpoint"
      ],
      "metadata": {
        "id": "bu7tEnllmod4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13f1d5b3-d919-422a-f8da-2840a0a77580"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    }
  ]
}