{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "S4DN-iBBZbQs"
      },
      "outputs": [],
      "source": [
        "# An implementation of https://arxiv.org/pdf/1512.03385.pdf\n",
        "# code was referenced from below\n",
        "# https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
      ],
      "metadata": {
        "id": "mkrREU9NfwS4"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 4\n",
        "batch_size = 100\n",
        "learning_rate = 0.001"
      ],
      "metadata": {
        "id": "ksztlrINfyA0"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Image preprocessing modules\n",
        "transform = transforms.Compose([\n",
        "    transforms.Pad(4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32),\n",
        "    transforms.ToTensor()])"
      ],
      "metadata": {
        "id": "1ChFfK_kf1Z_"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = torchvision.datasets.CIFAR10(root='../../data/',\n",
        "                                             train=True,\n",
        "                                             transform=transform,\n",
        "                                             download=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='../../data/',\n",
        "                                            train=False,\n",
        "                                            transform=transforms.ToTensor())\n",
        "\n",
        "# Data loader\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-cRwPqUf3Zf",
        "outputId": "eaff1037-8355-4a47-f9e0-5429a1364f90"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The residual block\n",
        "\n",
        "First we pass our ips through a  3x3 conv layer then we apply batch norm and pass through ReLU and then the second conv layer with a batch norm.\n",
        "\n",
        "DNN are hard to train\n",
        "The depth of the nw can be an obstacle to training.\n",
        "\n",
        "What happens when we pass data into such a deep network?\n",
        "\n",
        "We initialize a nn all of the layers have randomly chosen weights\n",
        "\n",
        "Then we pass inputs through each layer of networks the activtions are multiplied by a random weight matrix...okay\n",
        "\n",
        "After doing it many times, the data gets to the output layer\n",
        "\n",
        "Now its time to caculate the loss after forward pass\n",
        "\n",
        "When we pass gradients through back propagation, the loss calculated or the gradients we have now does not hold any value or meaning.\n",
        "After some forward passes, the layers may have an important information to hold, but it couldnt retain after so many layers ahead, therefore a residue( to understand) is extracted after every few layers and each few layers defined under a residual block in a residual network.\n",
        "\n",
        "Within each block, the layers will pass their data normally and between each block there is a new type of connection. This connection is called skip connection.\n",
        "\n",
        "And this connection works by combining input from the block to the output of the block.\n",
        "\n",
        "Now, we may make this connection by concatenating the i/p and o/p tensors.\n",
        "These skip connections accelerate the training.\n",
        "\n",
        "This will the network during backpropagation to hold meaningful falues whose loss is near to zero.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rQpAflRAtHyZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3x3 convolution\n",
        "def conv3x3(in_channels, out_channels, stride=1):\n",
        "    return nn.Conv2d(in_channels, out_channels, kernel_size=3,\n",
        "                     stride=stride, padding=1, bias=False)"
      ],
      "metadata": {
        "id": "KRSvYNnef6-o"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv1 = conv3x3(in_channels, out_channels, stride)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(out_channels, out_channels)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.downsample = downsample\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        if self.downsample:\n",
        "            residual = self.downsample(x)\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "TsrVIpB81tiW"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, layers, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_channels = 16\n",
        "        self.conv = conv3x3(3, 16)\n",
        "        self.bn = nn.BatchNorm2d(16)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.layer1 = self.make_layer(block, 16, layers[0])\n",
        "        self.layer2 = self.make_layer(block, 32, layers[1], 2)\n",
        "        self.layer3 = self.make_layer(block, 64, layers[2], 2)\n",
        "        self.avg_pool = nn.AvgPool2d(8)\n",
        "        self.fc = nn.Linear(64, num_classes)\n",
        "\n",
        "    def make_layer(self, block, out_channels, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if (stride != 1) or (self.in_channels != out_channels):\n",
        "            downsample = nn.Sequential(\n",
        "                conv3x3(self.in_channels, out_channels, stride=stride),\n",
        "                nn.BatchNorm2d(out_channels))\n",
        "        layers = []\n",
        "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
        "        self.in_channels = out_channels\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(out_channels, out_channels))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv(x)\n",
        "        out = self.bn(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.avg_pool(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "\n",
        "model = ResNet(ResidualBlock, [2, 2, 2]).to(device)"
      ],
      "metadata": {
        "id": "kYecMTyF12Fu"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "explanation:\n",
        "\n",
        "\n",
        "conv3x3 is a function that defines a 3x3 convolutional layer. In convolutional neural networks (CNNs), 3x3 convolutions are commonly used to capture spatial patterns in the input data.\n",
        "\n",
        "It takes input channels, output channels, and an optional stride as parameters.\n",
        "A stride of 1 means the kernel moves one pixel at a time.\n",
        "\n",
        "Adds a batch normalization layer (bn1) after the first convolution.\n",
        "Batch normalization helps stabilize and speed up training.\n",
        "\n",
        "\n",
        "Applies Rectified Linear Unit (ReLU) activation to introduce non-linearity. The inplace=True option modifies the input tensor directly, saving memory.\n",
        "self.conv2 = conv3x3(out_channels, out_channels)\n",
        "\n",
        "Creates the second 3x3 convolutional layer (conv2) with the same output channels. This convolutional layer further transforms the data.\n",
        "\n",
        "Adds a batch normalization layer (bn2) after the second convolution.\n",
        "\n",
        "The downsample parameter is assigned to the downsample attribute. This parameter is optional and provides a way to downsample the input if needed.\n",
        "\n",
        "forward:\n",
        "\n",
        "Defines the forward pass method for the ResidualBlock. This method specifies how data should flow through the block during forward propagation.\n",
        "\n",
        "Saves the original input (x) as the residual. This will be added to the transformed output later.\n",
        "\n",
        "Applies the first convolutional layer to the input.\n",
        "\n",
        "Applies batch normalization to the output of the first convolution.\n",
        "\n",
        "Applies ReLU activation.\n",
        "\n",
        "Applies the second convolutional layer.\n",
        "\n",
        "Applies batch normalization to the output of the second convolution.\n",
        "\n",
        "Checks if a downsample function is provided.\n",
        "\n",
        "If a downsample function is provided, applies it to the original input (x) to match dimensions.\n",
        "\n",
        "Adds the original input (residual) to the transformed output. This creates a shortcut connection.\n",
        "\n",
        "Applies ReLU activation to the final output.\n",
        "\n",
        "Returns the final output of the residual block after the forward pass."
      ],
      "metadata": {
        "id": "Vm6eFL5U5rI0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "We9eJRPj2EJU"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For updating learning rate\n",
        "def update_lr(optimizer, lr):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr"
      ],
      "metadata": {
        "id": "tACzsx788NRr"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_step = len(train_loader)\n",
        "curr_lr = learning_rate\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i+1) % 100 == 0:\n",
        "            print (\"Epoch [{}/{}], Step [{}/{}] Loss: {:.4f}\"\n",
        "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
        "\n",
        "    # Decay learning rate\n",
        "    if (epoch+1) % 20 == 0:\n",
        "        curr_lr /= 3\n",
        "        update_lr(optimizer, curr_lr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90CMUztc8PLI",
        "outputId": "91efc84a-1641-41ff-dc51-2a63f2de9a0f"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/4], Step [100/500] Loss: 1.7602\n",
            "Epoch [1/4], Step [200/500] Loss: 1.4141\n",
            "Epoch [1/4], Step [300/500] Loss: 1.2637\n",
            "Epoch [1/4], Step [400/500] Loss: 1.3798\n",
            "Epoch [1/4], Step [500/500] Loss: 1.0047\n",
            "Epoch [2/4], Step [100/500] Loss: 1.0096\n",
            "Epoch [2/4], Step [200/500] Loss: 1.0822\n",
            "Epoch [2/4], Step [300/500] Loss: 1.2242\n",
            "Epoch [2/4], Step [400/500] Loss: 0.8563\n",
            "Epoch [2/4], Step [500/500] Loss: 0.8088\n",
            "Epoch [3/4], Step [100/500] Loss: 0.7238\n",
            "Epoch [3/4], Step [200/500] Loss: 0.7976\n",
            "Epoch [3/4], Step [300/500] Loss: 0.7426\n",
            "Epoch [3/4], Step [400/500] Loss: 0.9967\n",
            "Epoch [3/4], Step [500/500] Loss: 0.8524\n",
            "Epoch [4/4], Step [100/500] Loss: 0.7132\n",
            "Epoch [4/4], Step [200/500] Loss: 0.8299\n",
            "Epoch [4/4], Step [300/500] Loss: 0.9029\n",
            "Epoch [4/4], Step [400/500] Loss: 0.6775\n",
            "Epoch [4/4], Step [500/500] Loss: 0.8872\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Accuracy of the model on the test images: {} %'.format(100 * correct / total))\n",
        "\n",
        "# Save the model checkpoint\n",
        "torch.save(model.state_dict(), 'resnet.ckpt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmmKiR8w8RUw",
        "outputId": "bfb1c09e-8212-4526-dd87-57c6108bdb0c"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the model on the test images: 72.37 %\n"
          ]
        }
      ]
    }
  ]
}